{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.python.platform\n",
    "from tensorflow.python.platform import gfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn import model_selection\n",
    "import sklearn.linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pickle\n",
    "import scipy.linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Pick k = 5 classes of your choice from the dataset. You may choose any subset of 5 classes among all classes of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_files(dir):\n",
    "    folders = []\n",
    "    for root, dirs, files in os.walk(dir):\n",
    "        for r in dirs:\n",
    "            folders.append(r)\n",
    "    return folders\n",
    "\n",
    "def list_directories(folders_list):\n",
    "    images_dirs = []\n",
    "    for i in range(len(folders)):\n",
    "        images_d = '/Users/jingyany/Desktop/17Spring/Data558/data competation/five classes/'+folders[i]+'/'\n",
    "        images_dirs.append(images_d)\n",
    "    return images_dirs\n",
    "\n",
    "def images_lists(images_dirs):\n",
    "    list_images = []\n",
    "    for i in range(len(images_dirs)):\n",
    "        images_dir = images_dirs[i]\n",
    "        for f in os.listdir(images_dir):\n",
    "            if re.search('jpg|JPG', f):\n",
    "                list_images.append(images_dir + f)\n",
    "    return list_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_dir = '/Users/jingyany/models/tutorials/image/imagenet/TUTORIAL_DIR/imagenet'\n",
    "dir = '/Users/jingyany/Desktop/17Spring/Data558/data competation/five classes'\n",
    "folders = list_files(dir)\n",
    "images_dirs = list_directories(folders)\n",
    "list_images = images_lists(images_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    with gfile.FastGFile(os.path.join(model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(list_images):\n",
    "    nb_features = 2048\n",
    "    features = np.empty((len(list_images),nb_features))\n",
    "    labels = []\n",
    "\n",
    "    create_graph()\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        next_to_last_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "\n",
    "    for ind, image in enumerate(list_images):\n",
    "        #if (ind%100 == 0):\n",
    "        print('Processing %s...' % (image))\n",
    "        if not gfile.Exists(image):\n",
    "            tf.logging.fatal('File does not exist %s', image)\n",
    "\n",
    "        image_data = gfile.FastGFile(image, 'rb').read()\n",
    "        predictions = sess.run(next_to_last_tensor,{'DecodeJpeg/contents:0': image_data})\n",
    "        features[ind,:] = np.squeeze(predictions)\n",
    "        labels.append(re.split('_\\d+',image.split('/')[-2].split('.')[0])[0])\n",
    "    labels = list(map(int, labels))\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#features,labels = extract_features(list_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Write a function that, for any class at hand, creates a training set with an equal number of examples from the class at hand and from the other classes. You may simply randomly pick the examples from the other classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pickle.load(open('features_5class','rb'))\n",
    "labels = pickle.load(open('labels_5class','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_training(features, labels, start, num=30):\n",
    "    if start == 0:\n",
    "        X_one_class = features[:num]\n",
    "        y_one_class = labels[:num]\n",
    "        X_other_classes = features[num:]\n",
    "        y_other_classes = labels[num:]\n",
    "    else: \n",
    "        X_one_class = features[start:(start+num)]\n",
    "        y_one_class = labels[start:(start+num)]\n",
    "        X_other_classes = np.concatenate([features[:start], features[(start+num):]])\n",
    "        y_other_classes = np.concatenate([labels[:start], labels[(start+num):]])\n",
    "    index = np.random.choice(y_other_classes.shape[0],num,False)\n",
    "    index = index.tolist()\n",
    "    y_other_classes_num= np.zeros(num)\n",
    "    X_other_classes_num = np.zeros((num,2048))\n",
    "    \n",
    "    for i in range(len(index)):\n",
    "        X_other_classes_num[i] = X_other_classes[index[i]]\n",
    "        y_other_classes_num[i] = y_other_classes[index[i]]\n",
    "        \n",
    "    return X_one_class, y_one_class, X_other_classes_num, y_other_classes_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) For each class c, train an $l_2^2$-regularized logistic regression classifier using your own fast gradient algorithm with $\\lambda_c$ = 1. Display the confusion matrix. Which classes seem to be the most difficult to classify?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def computegrad(beta, lamda, x, y):\n",
    "    n = len(y)\n",
    "    yx = y[:, None]*x\n",
    "    upper = yx*np.exp(-yx.dot(beta[:, None]))\n",
    "    bottom = np.exp(-yx.dot(beta))+1\n",
    "    gradient = -1/n *np.sum(upper/bottom[:, None], axis=0) + 2*lamda*beta\n",
    "                            \n",
    "    return gradient\n",
    "\n",
    "def function(beta, lamda, x, y):\n",
    "    n = len(y)\n",
    "    yx = y[:, None]*x\n",
    "    f = 1/n*(np.sum(np.log(np.exp(-yx.dot(beta))+1))) + lamda*np.linalg.norm(beta)**2\n",
    "    return f\n",
    "\n",
    "def backtracking(beta, lamda, t=1, alpha=0.5, beta_s=0.8, max_iter=100):\n",
    "    grad_beta = computegrad(beta, lamda, x=X_train, y=y_train)\n",
    "    norm_grad_beta = np.linalg.norm(grad_beta)\n",
    "    found_t = 0 \n",
    "    iter = 0 \n",
    "    while (found_t == 0 and iter < max_iter):       \n",
    "        if (function(beta - t*grad_beta, lamda, x=X_train, y=y_train)) < (function(beta, lamda, x=X_train, y=y_train)-alpha*t*(norm_grad_beta)**2):\n",
    "            found_t = 1        \n",
    "        elif(iter == max_iter):\n",
    "            stop(\"Maximum number of iterations reached\")         \n",
    "        else:\n",
    "            t = t*beta_s\n",
    "            iter = iter + 1   \n",
    "    return t \n",
    "\n",
    "def fastgradalgo(beta_init,theta,lamda,t_init, max_iter=500):\n",
    "    beta = beta_init\n",
    "    grad_theta = computegrad(beta, lamda, x=X_train, y=y_train)\n",
    "    beta_vals = theta\n",
    "    \n",
    "    iter = 0\n",
    "    while(iter < max_iter):         \n",
    "        t = backtracking(beta, lamda)\n",
    "        beta1 = theta - t*grad_theta\n",
    "        theta = beta1 + t/(t+3)*(beta1 - beta)\n",
    "        beta_vals = np.vstack((beta_vals, theta))\n",
    "        grad_theta = computegrad(theta, lamda, x=X_train, y=y_train)\n",
    "        beta = beta1\n",
    "        iter = iter + 1\n",
    "        \n",
    "    return beta_vals\n",
    "\n",
    "def get_predicted(beta_opt, x):\n",
    "    y_pred = 1/(1+np.exp(-x.dot(beta_opt))) > 0.5\n",
    "    y_pred = y_pred*2 - 1  # Convert to +/- 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def redefine_lables(labels, number):\n",
    "    for i in range(labels.shape[0]):\n",
    "        if labels[i] == number:\n",
    "            labels[i] = 1\n",
    "        else:\n",
    "            labels[i] = -1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training_test(X, y, X_rest, y_rest, number, first_class):\n",
    "    X_new = np.concatenate([X,X_rest])\n",
    "    y_new = np.concatenate([y,y_rest])\n",
    "    y_new = redefine_lables(y_new, first_class)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_new, y_new, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pred_test(X_train, X_test, y_train, y_test):\n",
    "    d = np.size(X_train, 1)\n",
    "    beta = np.zeros(d)\n",
    "    theta = np.zeros(d)\n",
    "    lambduh = 1\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "    fgd_betas = fastgradalgo(beta_init=beta,theta=theta,lamda=1,t_init=eta_init)\n",
    "    y_pred = get_predicted(fgd_betas[-1], X_test)\n",
    "    return y_pred \n",
    "\n",
    "#metrics.confusion_matrix(y_test1, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44,\n",
       "       44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44, 44])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use class 1 versus rest classes\n",
    "X1,y1,X_rest_1, y_rest_1 = create_training(features, labels, 0)\n",
    "y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = training_test(X1,y1,X_rest_1, y_rest_1, 0, 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train1\n",
    "y_train = y_train1\n",
    "y_pred1 = get_pred_test(X_train1, X_test1, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 -1  1 -1 -1 -1  1 -1 -1 -1]\n",
      "[ 1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred1)\n",
    "print(y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 1],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class1_cm = metrics.confusion_matrix(y_test1, y_pred1)\n",
    "class1_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45,\n",
       "       45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45, 45])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use class 2 versus rest classes\n",
    "X2,y2,X_rest_2, y_rest_2 = create_training(features, labels, 30)\n",
    "y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = training_test(X2,y2,X_rest_2, y_rest_2, 30, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train2\n",
    "y_train = y_train2\n",
    "y_pred2 = get_pred_test(X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1]\n",
      "[ 1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred2)\n",
    "print(y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [1, 3]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class2_cm = metrics.confusion_matrix(y_test2, y_pred2)\n",
    "class2_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46,\n",
       "       46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46, 46])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use class 3 versus rest classes\n",
    "X3,y3,X_rest_3, y_rest_3 = create_training(features, labels, 60)\n",
    "y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train3, X_test3, y_train3, y_test3 = training_test(X3,y3,X_rest_3, y_rest_3, 60, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train3\n",
    "y_train = y_train3\n",
    "y_pred3 = get_pred_test(X_train3, X_test3, y_train3, y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1]\n",
      "[ 1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred3)\n",
    "print(y_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class3_cm = metrics.confusion_matrix(y_test3, y_pred3)\n",
    "class3_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "       47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use class 4 versus rest classes\n",
    "X4,y4,X_rest_4, y_rest_4 = create_training(features, labels, 90)\n",
    "y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train4, X_test4, y_train4, y_test4 = training_test(X4,y4,X_rest_4, y_rest_4, 90, 47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train4\n",
    "y_train = y_train4\n",
    "y_pred4 = get_pred_test(X_train4, X_test4, y_train4, y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1 -1 -1  1 -1 -1 -1  1 -1 -1 -1]\n",
      "[ 1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred4)\n",
    "print(y_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class4_cm = metrics.confusion_matrix(y_test4, y_pred4)\n",
    "class4_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48,\n",
       "       48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use class 5 versus rest classes\n",
    "X5,y5,X_rest_5, y_rest_5 = create_training(features, labels, 120)\n",
    "y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train5, X_test5, y_train5, y_test5 = training_test(X5,y5,X_rest_5, y_rest_5, 120, 48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train5\n",
    "y_train = y_train5\n",
    "y_pred5 = get_pred_test(X_train5, X_test5, y_train5, y_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1  1  1 -1 -1 -1  1  1 -1  1]\n",
      "[ 1.  1. -1. -1.  1. -1. -1. -1.  1. -1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred5)\n",
    "print(y_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 4],\n",
       "       [0, 4]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class5_cm = metrics.confusion_matrix(y_test5, y_pred5)\n",
    "class5_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 1]\n",
      " [0 4]]\n",
      "[[8 0]\n",
      " [1 3]]\n",
      "[[8 0]\n",
      " [0 4]]\n",
      "[[8 0]\n",
      " [0 4]]\n",
      "[[4 4]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "print(class1_cm)\n",
    "print(class2_cm)\n",
    "print(class3_cm)\n",
    "print(class4_cm)\n",
    "print(class5_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anwser: class 5 seems to be the most difficult to classify, since the number of correctly predicted lables is the smallest among all 5 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Write a function that returns the ranked list of classes in terms of classification difficulty using the confusion matrix. Compute the multi-class misclassification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm_list = [class1_cm, class2_cm, class3_cm, class4_cm, class5_cm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ranked_list(matrix_list):\n",
    "    correct_list = []\n",
    "    ranked_list = []\n",
    "    for i in range(5):\n",
    "        correct = cm_list[i][0][0]+cm_list[i][1][1]\n",
    "        correct_list.append(correct)\n",
    "    for j in range(5):\n",
    "        class_num = np.argmin(correct_list)+1\n",
    "        ranked_list.append(class_num)\n",
    "        correct_list[np.argmin(correct_list)] = 13\n",
    "    return ranked_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 1, 2, 3, 4]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked_list(cm_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The multi-class misclassification error is 0.1\n"
     ]
    }
   ],
   "source": [
    "incorrect_list = []\n",
    "for i in range(5):\n",
    "    incorrect = cm_list[i][0][1]+cm_list[i][1][0]\n",
    "    incorrect_list.append(incorrect)\n",
    "print(\"The multi-class misclassification error is\", + sum(incorrect_list)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: the multi-class misclassification error of those 5 classes is about 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Find the values of the regularization parameters $\\lambda_1,..., \\lambda_k$ for the classifiers using a hold-out validation set strategy. Define a grid of values $\\Lambda$ for each parameter $\\lambda_c$ with c = 1,..., k. For each setting of the regularization parameters $\\lambda_1,..., \\lambda_k$, where each $\\lambda_c$ can take values in $\\Lambda$ (independently), train all your k = 5 classifiers and save the multi-class misclassification error on the validation set for each setting of the regularization parameters $\\lambda_1,..., \\lambda_k$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_misclassification_error(beta_opt, x, y):\n",
    "    y_pred = 1/(1+np.exp(-x.dot(beta_opt))) > 0.5\n",
    "    y_pred = y_pred*2 - 1 \n",
    "    return np.mean(y_pred != y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest misclassification error value: 0.0 at lambda = 0.001\n"
     ]
    }
   ],
   "source": [
    "#misclassification error for classifier 1\n",
    "lambdas = [10.0**i for i in np.arange(-3, 3, 1)]\n",
    "misclsf_error_1 = np.zeros_like(lambdas)\n",
    "for i in range(len(lambdas)):\n",
    "    lambduh = lambdas[i]\n",
    "    d = np.size(X_train1, 1)\n",
    "    beta_init = np.zeros(d)\n",
    "    X_train = X_train1\n",
    "    y_train = y_train1\n",
    "    X_test = X_test1\n",
    "    y_test = y_test1\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "    betas_rand = fastgradalgo(beta_init=beta_init,theta=beta_init,lamda=lambduh,t_init=eta_init)\n",
    "    misclsf_error_1[i] = compute_misclassification_error(betas_rand[-1], X_test, y_test)\n",
    "print('Smallest misclassification error value:', min(misclsf_error_1), 'at lambda =', lambdas[np.argmin(misclsf_error_1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest misclassification error value: 0.0 at lambda = 0.001\n"
     ]
    }
   ],
   "source": [
    "#misclassification error for classifier 2\n",
    "lambdas = [10.0**i for i in np.arange(-3, 3, 1)]\n",
    "misclsf_error_2 = np.zeros_like(lambdas)\n",
    "for i in range(len(lambdas)):\n",
    "    lambduh = lambdas[i]\n",
    "    d = np.size(X_train2, 1)\n",
    "    beta_init = np.zeros(d)\n",
    "    X_train = X_train2\n",
    "    y_train = y_train2\n",
    "    X_test = X_test2\n",
    "    y_test = y_test2\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "    betas_rand = fastgradalgo(beta_init=beta_init,theta=beta_init,lamda=lambduh,t_init=eta_init)\n",
    "    misclsf_error_1[i] = compute_misclassification_error(betas_rand[-1], X_test, y_test)\n",
    "print('Smallest misclassification error value:', min(misclsf_error_2), 'at lambda =', lambdas[np.argmin(misclsf_error_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest misclassification error value: 0.0 at lambda = 0.001\n"
     ]
    }
   ],
   "source": [
    "#misclassification error for classifier 3\n",
    "lambdas = [10.0**i for i in np.arange(-3, 3, 1)]\n",
    "misclsf_error_3 = np.zeros_like(lambdas)\n",
    "for i in range(len(lambdas)):\n",
    "    lambduh = lambdas[i]\n",
    "    d = np.size(X_train3, 1)\n",
    "    beta_init = np.zeros(d)\n",
    "    X_train = X_train3\n",
    "    y_train = y_train3\n",
    "    X_test = X_test3\n",
    "    y_test = y_test3\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "    betas_rand = fastgradalgo(beta_init=beta_init,theta=beta_init,lamda=lambduh,t_init=eta_init)\n",
    "    misclsf_error_1[i] = compute_misclassification_error(betas_rand[-1], X_test, y_test)\n",
    "print('Smallest misclassification error value:', min(misclsf_error_3), 'at lambda =', lambdas[np.argmin(misclsf_error_3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest misclassification error value: 0.0 at lambda = 0.001\n"
     ]
    }
   ],
   "source": [
    "#misclassification error for classifier 4\n",
    "lambdas = [10.0**i for i in np.arange(-3, 3, 1)]\n",
    "misclsf_error_4 = np.zeros_like(lambdas)\n",
    "for i in range(len(lambdas)):\n",
    "    lambduh = lambdas[i]\n",
    "    d = np.size(X_train4, 1)\n",
    "    beta_init = np.zeros(d)\n",
    "    X_train = X_train4\n",
    "    y_train = y_train4\n",
    "    X_test = X_test4\n",
    "    y_test = y_test4\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "    betas_rand = fastgradalgo(beta_init=beta_init,theta=beta_init,lamda=lambduh,t_init=eta_init)\n",
    "    misclsf_error_1[i] = compute_misclassification_error(betas_rand[-1], X_test, y_test)\n",
    "print('Smallest misclassification error value:', min(misclsf_error_4), 'at lambda =', lambdas[np.argmin(misclsf_error_4)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest misclassification error value: 0.0 at lambda = 0.001\n"
     ]
    }
   ],
   "source": [
    "#misclassification error for classifier 5\n",
    "lambdas = [10.0**i for i in np.arange(-3, 3, 1)]\n",
    "misclsf_error_5 = np.zeros_like(lambdas)\n",
    "for i in range(len(lambdas)):\n",
    "    lambduh = lambdas[i]\n",
    "    d = np.size(X_train5, 1)\n",
    "    beta_init = np.zeros(d)\n",
    "    X_train = X_train5\n",
    "    y_train = y_train5\n",
    "    X_test = X_test5\n",
    "    y_test = y_test5\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "    betas_rand = fastgradalgo(beta_init=beta_init,theta=beta_init,lamda=lambduh,t_init=eta_init)\n",
    "    misclsf_error_1[i] = compute_misclassification_error(betas_rand[-1], X_test, y_test)\n",
    "print('Smallest misclassification error value:', min(misclsf_error_5), 'at lambda =', lambdas[np.argmin(misclsf_error_5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) Find the optimal value of the regularization parameters $\\lambda_1,..., \\lambda_k$ based on the validation error. Display the confusion matrix for this setting of the regularization param-\n",
    "eters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The optimal lambda is 0.001 for all five classifiers\n",
    "def get_pred_test_opt(X_train, X_test, y_train, y_test):\n",
    "    d = np.size(X_train, 1)\n",
    "    beta = np.zeros(d)\n",
    "    theta = np.zeros(d)\n",
    "    lambduh = 0.001\n",
    "    eta_init = 1/(scipy.linalg.eigh(1/len(y_train)*X_train.T.dot(X_train), eigvals=(d-1, d-1), eigvals_only=True)[0]+lambduh)\n",
    "    fgd_betas = fastgradalgo(beta_init=beta,theta=theta,lamda=1,t_init=eta_init)\n",
    "    y_pred = get_predicted(fgd_betas[-1], X_test)\n",
    "    return y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train1\n",
    "y_train = y_train1\n",
    "y_pred1_opt = get_pred_test_opt(X_train1, X_test1, y_train1, y_test1)\n",
    "class1_cm_opt = metrics.confusion_matrix(y_test1, y_pred1_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train2\n",
    "y_train = y_train2\n",
    "y_pred2_opt = get_pred_test_opt(X_train2, X_test2, y_train2, y_test2)\n",
    "class2_cm_opt = metrics.confusion_matrix(y_test2, y_pred2_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train3\n",
    "y_train = y_train3\n",
    "y_pred3_opt = get_pred_test_opt(X_train3, X_test3, y_train3, y_test3)\n",
    "class3_cm_opt = metrics.confusion_matrix(y_test3, y_pred3_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train4\n",
    "y_train = y_train4\n",
    "y_pred4_opt = get_pred_test_opt(X_train4, X_test4, y_train4, y_test4)\n",
    "class4_cm_opt = metrics.confusion_matrix(y_test4, y_pred4_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train5\n",
    "y_train = y_train5\n",
    "y_pred5_opt = get_pred_test_opt(X_train5, X_test5, y_train5, y_test5)\n",
    "class5_cm_opt = metrics.confusion_matrix(y_test5, y_pred5_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 1]\n",
      " [0 4]]\n",
      "[[8 0]\n",
      " [1 3]]\n",
      "[[8 0]\n",
      " [0 4]]\n",
      "[[8 0]\n",
      " [0 4]]\n",
      "[[4 4]\n",
      " [0 4]]\n"
     ]
    }
   ],
   "source": [
    "print(class1_cm_opt)\n",
    "print(class2_cm_opt)\n",
    "print(class3_cm_opt)\n",
    "print(class4_cm_opt)\n",
    "print(class5_cm_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
